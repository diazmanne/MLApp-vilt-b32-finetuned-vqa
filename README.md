# README.md

# Visual Question Answering with ViLT

A step-by-step tutorial implementing Visual Question Answering using ViLT (Vision-and-Language Transformer).

## Concepts

1. **ViLT Model**: Vision-and-Language Transformer that processes both images and text in a single unified architecture
2. **Visual Question Answering**: Task where the model answers natural language questions about images
3. **Transformer Processing**: How the model jointly encodes visual and textual information

## Requirements

- Python 3.10+
- Libraries: `transformers`, `Pillow`, `requests`

## Installation

```bash
pip install transformers Pillow requests